// Generated by CoffeeScript 1.12.2
(function() {
  var ActivateFunc, ErrorFunc, Layer, LayerOf, Random, Variable, VariableOf, Variable_map_binary, Zero, _, add, assert, calcRMSError, deepcopy, div, dot, jam, main, mul, normSqr, numeric, pow, sub, sum, tensor, train, train_2, unit_test,
    indexOf = [].indexOf || function(item) { for (var i = 0, l = this.length; i < l; i++) { if (i in this && this[i] === item) return i; } return -1; };

  numeric = require('numeric');

  deepcopy = require('deepcopy');

  jam = require('./jam');

  _ = require('lodash');

  Function.prototype.property = function(prop, desc) {
    return Object.defineProperty(this.prototype, prop, desc);
  };

  assert = function(condition) {
    if (!condition) {
      throw "Assertion failed";
    }
  };

  Zero = function() {
    return 0.0;
  };

  Random = function() {
    return Math.random();
  };

  Variable_map_binary = function(f) {
    return function(a, b) {
      return VariableOf(f(a.data, b.data));
    };
  };

  add = Variable_map_binary(numeric.add);

  sub = Variable_map_binary(numeric.sub);

  dot = Variable_map_binary(numeric.dot);

  mul = Variable_map_binary(numeric.mul);

  div = Variable_map_binary(numeric.div);

  tensor = Variable_map_binary(numeric.tensor);

  pow = (function() {
    return function(a, b) {
      if (a.data instanceof Array) {
        return (Variable_map_binary(numeric.pow))(a, b);
      } else if (typeof a.data === 'number') {
        return (Variable_map_binary(Math.pow))(a, b);
      }
    };
  })();

  normSqr = jam.map(numeric.norm2Squared);

  sum = jam.map(numeric.sum);

  Variable = (function() {
    "Basic brick in neuron network.";
    function Variable(num_row, num_col, option) {
      var data, i, initializer, j;
      if (option == null) {
        option = {};
      }
      this._c_param = {
        num_row: 0,
        num_col: 0
      };
      this._m_state = {
        data: 0
      };
      if (num_row instanceof Array) {
        data = deepcopy(num_row);
        this._c_param.num_col = typeof data[0] === 'number' ? data.length : data[0].length;
        this._c_param.num_row = typeof data[0] === 'number' ? 1 : data.length;
        this._m_state.data = data;
      } else if (typeof num_row === 'number' && typeof num_col !== 'number') {
        data = num_row;
        this._c_param.num_col = this._c_param.num_row = 1;
        this._m_state.data = data;
      } else if (typeof num_row === 'number' && typeof num_col === 'number') {
        if ((option.initializer != null) && isNaN(option.initializer())) {
          throw TypeError("Error: option.initializer :: Void -> Double");
        }
        if (num_row < 1 || num_col < 1) {
          throw TypeError("Error: num_row and num_col must bigger than 0");
        }
        this._c_param.num_col = num_col;
        this._c_param.num_row = num_row;
        initializer = deepcopy(option).initializer;
        if (initializer == null) {
          initializer = Zero;
        }
        if (num_row === 1 && num_col === 1) {
          this._m_state.data = initializer();
        } else if (num_row === 1 && num_col !== 1) {
          this._m_state.data = (function() {
            var k, ref, results;
            results = [];
            for (i = k = 0, ref = num_col; 0 <= ref ? k < ref : k > ref; i = 0 <= ref ? ++k : --k) {
              results.push(initializer());
            }
            return results;
          })();
        } else {
          this._m_state.data = (function() {
            var k, ref, results;
            results = [];
            for (j = k = 0, ref = num_row; 0 <= ref ? k < ref : k > ref; j = 0 <= ref ? ++k : --k) {
              results.push((function() {
                var l, ref1, results1;
                results1 = [];
                for (i = l = 0, ref1 = num_col; 0 <= ref1 ? l < ref1 : l > ref1; i = 0 <= ref1 ? ++l : --l) {
                  results1.push(initializer());
                }
                return results1;
              })());
            }
            return results;
          })();
        }
      } else {
        throw TypeError("Error: no case matched");
      }
      this;
    }

    Variable.property('num_col', {
      get: function() {
        return this._c_param.num_col;
      }
    });

    Variable.property('num_row', {
      get: function() {
        return this._c_param.num_row;
      }
    });

    Variable.property('is_vector', {
      get: function() {
        return this._c_param.num_row === 1 && this._c_param.num_col > 1;
      }
    });

    Variable.property('is_number', {
      get: function() {
        return this._c_param.num_row === 1 && this._c_param.num_col === 1;
      }
    });

    Variable.property('data', {
      get: function() {
        return this._m_state.data;
      }
    });

    Variable.prototype.toString = function() {
      return "[Variable Object] Size: " + this._c_param.num_row + "x" + this._c_param.num_col;
    };

    Variable.prototype.map = function(f) {
      var data;
      data = f(this._m_state.data);
      return VariableOf(data);
    };

    Variable.prototype.clone = function() {
      return VariableOf(this._m_state.data);
    };

    return Variable;

  })();

  VariableOf = function(num_row, num_col, option) {
    return new Variable(num_row, num_col, option);
  };

  ActivateFunc = {
    identity: function(x) {
      return x;
    },
    identityDerivative: function() {
      return 1.0;
    },
    tanh: function(x) {
      return Math.tanh(x);
    },
    tanhDerivative: function(x) {
      return 1.0 - x * x;
    },
    logistic: function(x) {
      return 1.0 / (1.0 + Math.exp(-x));
    },
    logisticDerivative: function(y) {
      return y * (1 - y);
    },
    derivative: function(x) {
      switch (x.describe) {
        case 'identity':
          return ActivateFunc.identityDerivative;
        case 'tanh':
          return ActivateFunc.tanhDerivative;
        case 'logistic':
          return ActivateFunc.logisticDerivative;
        default:
          throw TypeError("Error: no derivate exist.");
      }
    }
  };

  ActivateFunc.identity.describe = 'identity';

  ActivateFunc.identityDerivative.describe = 'identityDerivative';

  ActivateFunc.tanh.describe = 'tanh';

  ActivateFunc.tanhDerivative.describe = 'tanhDerivative';

  ActivateFunc.logistic.describe = 'logistic';

  ActivateFunc.logisticDerivative.describe = 'logisticDerivative';

  ErrorFunc = {
    halfSquaredError: function(output, target) {
      var temp;
      temp = sub(target, output);
      temp = pow(temp, VariableOf(2));
      return div(temp, VariableOf(2));
    }
  };

  Layer = (function() {
    "Layer Monad.";
    function Layer(W, b, option) {
      var activate, activate_derivative;
      if (option == null) {
        option = {};
      }
      this._input = {
        data: void 0
      };
      this._output = {
        data: void 0
      };
      this._m_state = {
        W: deepcopy(W),
        b: deepcopy(b),
        W_delta: VariableOf(W.num_row, W.num_col, {
          initializer: Zero
        }),
        b_delta: VariableOf(b.num_row, b.num_col, {
          initializer: Zero
        }),
        gradient: VariableOf(b.num_row, b.num_col, {
          initializer: Zero
        })
      };
      this._c_param = {
        activate: void 0,
        activate_derivative: void 0
      };
      activate = option.activate;
      if (activate == null) {
        activate = ActivateFunc.identity;
      }
      activate_derivative = ActivateFunc.derivative(activate);
      this._c_param.activate = b.is_vector ? jam.map(jam.map(activate)) : jam.map(activate);
      this._c_param.activate_derivative = b.is_vector ? jam.map(jam.map(activate_derivative)) : jam.map(activate_derivative);
      this._c_param.activate.describe = activate.describe;
      this._c_param.activate_derivative.describe = activate_derivative.describe;
    }

    Layer.property('output', {
      get: function() {
        var temp;
        if (!(this._input.data != null)) {
          throw ReferenceError("Error: please set input before get ouput");
        }
        temp = dot(this._m_state.W, this._input.data);
        temp = add(temp, this._m_state.b);
        return deepcopy(this._output.data = this._c_param.activate(temp));
      }
    });

    Layer.property('input', {
      set: function(x) {
        return this._input.data = deepcopy(x);
      }
    });

    Layer.prototype.calcOutputGrad = function(target) {
      var contrib, derivate;
      this._output.data = this.output;
      contrib = sub(this._output.data, target);
      derivate = this._c_param.activate_derivative(this._output.data);
      this._m_state.gradient = mul(contrib, derivate);
      return void 0;
    };

    Layer.prototype.calcHiddenGrad = function(next) {
      var contrib, derivate;
      if (!(this._output.data != null)) {
        this._output.data = this.output;
      }
      contrib = dot(next._m_state.gradient, next._m_state.W);
      derivate = this._c_param.activate_derivative(this._output.data);
      this._m_state.gradient = mul(contrib, derivate);
      return void 0;
    };

    Layer.prototype.updateWeights = function(eta, alpha) {
      "newDeltaWeight = \n  // Global learning rate\n  eta\n  * prev_neuron.outputVal\n  * this_gradient\n  // Momentum, i.o.w old deltaWeight's memory\n  + alpha\n  * oldDeltaWeight";
      var delta_bias, delta_weight, temp;
      temp = tensor(this._m_state.gradient, this._input.data);
      temp = mul(eta, temp);
      delta_weight = add(temp, mul(alpha, this._m_state.W_delta));
      this._m_state.W_delta = delta_weight;
      this._m_state.W = sub(this._m_state.W, this._m_state.W_delta);
      temp = mul(eta, this._m_state.gradient);
      delta_bias = add(temp, mul(alpha, this._m_state.b_delta));
      this._m_state.b_delta = delta_bias;
      this._m_state.b = sub(this._m_state.b, this._m_state.b_delta);
      return void 0;
    };

    return Layer;

  })();

  LayerOf = function(input, W, b, activate, option) {
    return new Layer(input, W, b, activate, option);
  };

  calcRMSError = function(delta) {
    var error;
    error = jam.map(function(x) {
      return x.reduce(function(acc, val) {
        return acc + val * val;
      }, 0);
    })(delta);
    error = div(error, VariableOf([delta.num_col]));
    return error = jam.map(Math.sqrt)(error);
  };

  unit_test = function() {
    var W, W2, alpha, bias, bias2, eta, half_square_test_error, input, l1, l1_new_weights, l1_test_out, l2, l2_new_weights, l2_test_out, target;
    input = VariableOf([0.05, 0.1]);
    target = VariableOf([0.01, 0.99]);
    W = VariableOf([[0.15, 0.20], [0.25, 0.30]]);
    bias = VariableOf([0.35, 0.35]);
    W2 = VariableOf([[0.40, 0.45], [0.50, 0.55]]);
    bias2 = VariableOf([0.60, 0.60]);
    eta = VariableOf(0.5);
    alpha = VariableOf(0.0);
    l1_test_out = VariableOf([0.5932699921071872, 0.596884378259767]);
    l2_test_out = VariableOf([0.7513650695523157, 0.7729284653214625]);
    l2_new_weights = VariableOf([[0.35891647971788465, 0.4086661860762334], [0.5113012702387375, 0.5613701211079891]]);
    l1_new_weights = VariableOf([[0.1497807161327628, 0.19956143226552567], [0.24975114363236958, 0.29950228726473915]]);
    half_square_test_error = VariableOf(0.2983711087600027);
    l1 = LayerOf(W, bias, {
      activate: ActivateFunc.logistic
    });
    l2 = LayerOf(W2, bias2, {
      activate: ActivateFunc.logistic
    });
    return (function() {
      var error;
      l1.input = input;
      l2.input = l1.output;
      error = ErrorFunc.halfSquaredError(l2.output, target);
      l2.calcOutputGrad(target);
      l1.calcHiddenGrad(l2);
      assert(_.isEqual(l1.output.data, l1_test_out.data));
      assert(_.isEqual(l2.output.data, l2_test_out.data));
      assert(_.isEqual(sum(error), half_square_test_error));
      l2.updateWeights(eta, alpha);
      l1.updateWeights(eta, alpha);
      assert(_.isEqual(l2._m_state.W, l2_new_weights));
      assert(_.isEqual(l1._m_state.W, l1_new_weights));
      return console.log("Message: Unit test [PASS].");
    })();
  };

  unit_test();

  train_2 = function() {
    var W, W2, alpha, bias, bias2, eta, input, l1, l2, target;
    input = VariableOf([0.05, 0.1]);
    target = VariableOf([0.01, 0.99]);
    W = VariableOf(2, 2, {
      initializer: function() {
        return Math.random() * 0.5;
      }
    });
    bias = VariableOf(1, 2, {
      initializer: function() {
        return 0.1;
      }
    });
    W2 = VariableOf(2, 2, {
      initializer: function() {
        return Math.random() * 0.5;
      }
    });
    bias2 = VariableOf(1, 2, {
      initializer: function() {
        return 0.1;
      }
    });
    eta = VariableOf(0.5);
    alpha = VariableOf(0.0);
    l1 = LayerOf(W, bias, {
      activate: ActivateFunc.logistic
    });
    l2 = LayerOf(W2, bias2, {
      activate: ActivateFunc.logistic
    });
    return (function() {
      var i, k, results;
      results = [];
      for (i = k = 0; k <= 10000; i = ++k) {
        l1.input = input;
        l2.input = l1.output;
        l2.calcOutputGrad(target);
        l1.calcHiddenGrad(l2);
        l2.updateWeights(eta, alpha);
        l1.updateWeights(eta, alpha);
        if (i % 100 === 0) {
          results.push(console.log("Predict " + l2.output.data + ", target " + target.data));
        } else {
          results.push(void 0);
        }
      }
      return results;
    })();
  };

  train = function() {
    var W, W2, alpha, bias, bias2, eta, l1, l2, train_data;
    train_data = [
      {
        input: [0.0001, 0.0001],
        target: 1.0
      }, {
        input: [1.0, 0.001],
        target: 0.0001
      }, {
        input: [1.0, 1.0],
        target: 1.0
      }, {
        input: [0.0001, 1.0],
        target: 0.0001
      }
    ];
    eta = VariableOf(0.2);
    alpha = VariableOf(0.1);
    W = VariableOf(5, 2, {
      initializer: function() {
        return Math.random() * 0.5;
      }
    });
    bias = VariableOf(1, 5, {
      initializer: function() {
        return 0.1;
      }
    });
    W2 = VariableOf(1, 5, {
      initializer: function() {
        return Math.random() * 0.5;
      }
    });
    bias2 = VariableOf(1, 1, {
      initializer: function() {
        return 0.1;
      }
    });
    l1 = LayerOf(W, bias, {
      activate: ActivateFunc.logistic
    });
    l2 = LayerOf(W2, bias2, {
      activate: ActivateFunc.logistic
    });
    return (function() {
      var i, input, k, ref, ref1, results, target, temp;
      results = [];
      for (i = k = 0; k <= 1000000; i = ++k) {
        ref = train_data[i % 4], input = ref.input, target = ref.target;
        input = VariableOf(input);
        target = VariableOf(target);
        l1.input = input;
        l2.input = l1.output;
        temp = l2.output;
        l2.calcOutputGrad(target);
        l1.calcHiddenGrad(l2);
        l2.updateWeights(eta, alpha);
        l1.updateWeights(eta, alpha);
        if (ref1 = i % 10, indexOf.call([0, 1, 2, 3], ref1) >= 0) {
          results.push(console.log("Predict: " + l2.output.data + ", Target: " + target.data));
        } else {
          results.push(void 0);
        }
      }
      return results;
    })();
  };

  (main = function() {
    return train();
  })();

}).call(this);

//# sourceMappingURL=app.js.map
